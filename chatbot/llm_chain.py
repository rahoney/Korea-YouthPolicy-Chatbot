from __future__ import annotations
from typing import Dict, Any, List

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain

from chatbot.retrieval import hybrid_retrieve   # ë¦¬íŠ¸ë¦¬ë²„ í•¨ìˆ˜

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) LLM ì´ˆê¸°í™” (Gemini-2.0-flash)
# ----------------------------------------------
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0.2,
    top_p=0.9
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# ----------------------------------------------
# ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­
system_instruction = """
- ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•´ì„œ ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
- ì§ˆë¬¸ì† ëª¨ë“  ì¡°ê±´ì— ë¶€í•©í•˜ëŠ” ì •ì±…ì´ ì—†ë‹¤ë©´ "í•´ë‹¹í•˜ëŠ” ì •ì±…ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ê°„ë‹¨í•˜ê²Œ ë‹µí•´ìš”.
- ìµœì†Œë‚˜ì´ì™€ ìµœëŒ€ë‚˜ì´ ì¡°ê±´ì„ í™•ì¸í•´ ì§ˆë¬¸ì˜ ë‚˜ì´ê°€ ê·¸ ì‚¬ì´ì— í•´ë‹¹í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
- ë°ì´í„°ì˜ ìµœëŒ€ë‚˜ì´ê°€ ê³µëž€ ë˜ëŠ” 0ì´ë¼ë©´ í•´ë‹¹ í•­ëª©ì˜ ë‚˜ì´ ì œí•œì´ ì—†ëŠ” ê±°ì—ìš”.
- ì§ˆë¬¸ì—ì„œ ì§€ì—­, ë‚˜ì´, ì •ì±… ë“± ì¡°ê±´ì— ëª¨ë‘ ë¶€í•©í•˜ëŠ” ê²ƒì„ ë°ì´í„°ì—ì„œ ì°¾ìœ¼ì„¸ìš”.
- ê°€ìƒì˜ ì •ì±…ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”. ì‹¤ì œ ì •ì±… ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- ì§ˆë¬¸ì— ë¼ì›Œë§žì¶° ê¸°ì¡´ ì •ì±…ì„ ê°€ê³µí•˜ì§€ë§ˆì„¸ìš”.
- ìµœì¢… ìˆ˜ì •ì¼ì´ ê°€ìž¥ ìµœê·¼ì— ëœ ê²ƒìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- URLì´ ì‹ ì²­url, ì¹¨ê³ url ëª¨ë‘ ì—†ë‹¤ë©´ ì‹ ì²­ ë°©ë²•ì´ë‚˜ ë‹¤ë¥¸ í•­ëª© ë°ì´í„°ì— ìžˆëŠ”ì§€ ì°¾ì•„ì£¼ì„¸ìš”. ì—†ë‹¤ë©´ ìš´ì˜ê¸°ê´€ ê³µì‹ í™ˆíŽ˜ì´ì§€ urlì„ ë„£ì–´ì£¼ì„¸ìš”.
- ë‹µë³€í•  í•­ëª©ì˜ ë°ì´í„°ê°€ ì—†ë‹¤ë©´ "ë“±ë¡ê¸°ê´€ì—ì„œ ë°ì´í„°ë¥¼ ë¯¸ë“±ë¡í•˜ì˜€ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.(urlí•­ëª© ì œì™¸)
- ë§Œì•½ ë¬¸ì˜í•  ì—°ë½ì²˜ê°€ ë°ì´í„° ì–´ë””ì—ë„ ì—†ë‹¤ë©´ ìš´ì˜ê¸°ê´€ì˜ ê³µì‹ ì—°ë½ì²˜ë¥¼ ì¸í„°ë„·ì—ì„œ ì°¾ì•„ì„œ ë„£ì–´ì£¼ì„¸ìš”.
- ë¶€ë™ì‚° ì§ˆë¬¸ì´ ìžˆë‹¤ë©´ ì£¼ê±°ì— ëŒ€í•œ ì§ˆë¬¸ì´ì—ìš”.
"""
# ì‹œìŠ¤í…œ ë©”ì‹œì§€ í”„ë¡¬í”„íŠ¸
system_prompt = SystemMessagePromptTemplate.from_template(system_instruction)

# ì‚¬ìš©ìž ìž…ë ¥ í”„ë¡¬í”„íŠ¸
user_prompt = HumanMessagePromptTemplate.from_template(
    """
    ì‚¬ìš©ìž ì§ˆë¬¸: {question}\n\n
    ì•„ëž˜ëŠ” ì§ˆë¬¸ê³¼ ê´€ë ¨í•˜ì—¬ ê²€ìƒ‰ëœ ì •ì±… ë‚´ìš©ìž…ë‹ˆë‹¤.
    ì§ˆë¬¸ì—ì„œ ì œì‹œí•œ ì§€ì—­ ì¡°ê±´ì— ì •í™•ížˆ ë§žëŠ” ì •ì±…ì„ ê°€ìž¥ ë¨¼ì € ìš°ì„ ì ìœ¼ë¡œ ë‹µë³€ì— ìž‘ì„±í•´ì£¼ì„¸ìš”:\n
    ì´ ì •ì±…ë“¤ì€ ì•žì„  ë‹¨ê³„ì—ì„œ LLMì— ì˜í•´ ì •í™•í•œ í‰ê°€ ê¸°ì¤€(ì§€ì—­, ë‚˜ì´, ì •ì±… ë‚´ìš©)ì— ë”°ë¼ ì ìˆ˜ê°€ ë§¤ê²¨ì¡ŒìŠµë‹ˆë‹¤.
    ì ìˆ˜ê°€ ê°€ìž¥ ë†’ì€ ì •ì±…ë¶€í„° ê°€ìž¥ ë‚®ì€ ì •ì±… ìˆœìœ¼ë¡œ ë‚˜ì—´ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.

    {context}
    ìœ„ ì •ì±… ì¤‘ ì ìˆ˜ê°€ ê°€ìž¥ ë†’ì€ ì²« ë²ˆì§¸ ì •ì±…ë¶€í„° ìš°ì„ ì ìœ¼ë¡œ ì•„ëž˜ í˜•ì‹ì— ë§žì¶° ë‹µë³€ì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.
    ì ìˆ˜ê°€ ë†’ì•„ë„ ì§ˆë¬¸ì† ëª¨ë“  ì¡°ê±´ì— ë¶€í•©í•˜ì§€ ì•Šìœ¼ë©´ "í•´ë‹¹í•˜ëŠ” ì •ì±…ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ê°„ë‹¨í•˜ê²Œ ë‹µí•´ìš”.

    ðŸ“Œ ì •ì±…ëª…: [ì •ì±… ì´ë¦„]\n
    ðŸ“ ì •ì±… ì„¤ëª…: [ì •ì±…ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…]\n\n
    ðŸ“Œ ì§€ì› ë‚´ìš©:\n
    âœ”ï¸ [ì§€ì› í•­ëª© 1]\n
    âœ”ï¸ [ì§€ì› í•­ëª© 2]\n
    âœ”ï¸ [ì§€ì› í•­ëª© 3]\n\n
    ðŸ“Œ ì‹ ì²­ ì¡°ê±´:\n
    ðŸ“ [ì‹ ì²­ ì¡°ê±´ 1]\n
    ðŸ“ [ì‹ ì²­ ì¡°ê±´ 2]\n
    ðŸ“ ì—°ë ¹ ì œí•œ:\n\n
    ðŸ“Œ ì‚¬ì—… ê¸°ê°„:\n
    ðŸ“Œ ì‹ ì²­ ë°©ë²•:\n
    ðŸ“Œ ê¸°íƒ€ ì‚¬í•­:\n
    ðŸ“Œ ì œì¶œ ì„œë¥˜:\n\n
    ðŸ“Œ ì£¼ê´€ ê¸°ê´€:\n
    ðŸ“Œ ìš´ì˜ ê¸°ê´€:\n
    ðŸ“Œ ë¬¸ì˜ & ì¶”ê°€ ì •ë³´:\n
    ðŸ“ž ê´€ë ¨ ê¸°ê´€ ë¬¸ì˜: [ë¬¸ì˜ì²˜]\n
    ðŸ”— ì°¸ê³  URL: [ì—†ë‹¤ë©´ '-' í‘œê¸°]\n
    ----------------------------------------------------------------\n
    """
    )

# ChatPromptTemplate ìƒì„±
prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])
qa_chain = LLMChain(llm=llm, prompt=prompt)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ì²´ì¸ ë¹Œë”
# ----------------------------------------------
def build_chain(k: int = 5) -> LLMChain:
    """
    k: hybrid_retrieve top-k
    """
    def _make_inputs(question: str) -> Dict[str, str]:
        docs = hybrid_retrieve(question, k=k)
        context = "\n\n".join(
            f"[{d.metadata.get('doc_id')}] {d.page_content[:800]}"
            for d in docs
        ) or "NONE"
        return {"question": question, "context": context}

    class _Wrapper(LLMChain):
        def run(self, inputs: Dict[str, str] | str) -> str:
            if isinstance(inputs, str):
                inputs = {"question": inputs}
            full_inputs = _make_inputs(inputs["question"])
            return super().run(full_inputs)

    return _Wrapper(llm=llm, prompt=prompt)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ì‚¬ìš© ì˜ˆì‹œ (ë‹¨ë… ì‹¤í–‰)
# ----------------------------------------------
if __name__ == "__main__":
    qa = build_chain(k=5)
    while True:
        q = input("ì§ˆë¬¸(q to quit) > ").strip()
        if q.lower() in {"q", "quit", "exit"}:
            break
        print(qa.run({"question": q}))
        print("-" * 60)
